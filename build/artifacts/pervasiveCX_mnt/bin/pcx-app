#!/usr/bin/env python3
import http.server
import socketserver
import os
import json
import subprocess
import urllib.parse
from datetime import datetime
from pathlib import Path

# Paths on installed systems
APP_ENV_FILE = "/pervasiveCX_mnt/config/app.env"
WEB_ROOT = "/pervasiveCX_mnt/web"
LOG_FILE = "/pervasiveCX_mnt/logs/web/pervasiveCX-web.log"

os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)


def log(level: str, message: str):
    now = datetime.now().isoformat()
    line = json.dumps({
        "timestamp": now,
        "level": level,
        "component": "web",
        "service": "pcx-app",
        "message": message,
    })
    with open(LOG_FILE, "a") as f:
        f.write(line + "\n")
    print(line)


def load_env():
    """Load PCX_* variables from app.env, if present."""
    if not os.path.isfile(APP_ENV_FILE):
        log("ERROR", f"app.env not found at {APP_ENV_FILE}")
        return

    with open(APP_ENV_FILE) as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#") or "=" not in line:
                continue
            k, v = line.split("=", 1)
            k = k.strip()
            v = v.strip().strip('"').strip("'")
            os.environ.setdefault(k, v)

    log("INFO", f"Loaded environment from {APP_ENV_FILE}")


def _psql_env():
    """
    Build environment for psql based on PCX_DB_PASS.
    Does not hard-code host/user, only PGPASSWORD.
    """
    env = os.environ.copy()
    db_pass = os.environ.get("PCX_DB_PASS", "").strip()
    if db_pass:
        env["PGPASSWORD"] = db_pass
    else:
        env.pop("PGPASSWORD", None)
    return env


def run_psql_query(sql: str):
    """
    Run SQL via psql using PCX_* variables.

    - PCX_DB_NAME (default: pervasivecx)
    - PCX_DB_USER (default: postgres)
    - PCX_DB_HOST (optional; if empty -> no -h)
    - PCX_DB_PORT (optional; if empty -> no -p)
    """
    db_name = os.environ.get("PCX_DB_NAME", "pervasivecx").strip()
    db_user = os.environ.get("PCX_DB_USER", "postgres").strip()
    db_host = os.environ.get("PCX_DB_HOST", "").strip()
    db_port = os.environ.get("PCX_DB_PORT", "").strip()

    cmd = ["psql", "-At"]

    # Only add host/port if set â€“ avoids the -h '' issue
    if db_host:
        cmd.extend(["-h", db_host])
    if db_port:
        cmd.extend(["-p", db_port])

    cmd.extend(["-d", db_name, "-U", db_user, "-c", sql])

    try:
        result = subprocess.run(
            cmd,
            env=_psql_env(),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True,
            check=True,
        )
        return result.stdout.strip().splitlines()
    except subprocess.CalledProcessError as e:
        log("ERROR", f"psql failed: {e.stderr.strip()} (cmd={' '.join(cmd)})")
        raise


def trigger_full_capture():
    """Call the collector script under /pervasiveCX_mnt/bin on client systems."""
    collector = "/pervasiveCX_mnt/bin/pcx-collector"
    if not os.path.isfile(collector):
        log("ERROR", f"pcx-collector not found at {collector}")
        return False
    try:
        log("INFO", "Triggering pcx-collector full...")
        subprocess.run([collector, "full"], check=True)
        log("INFO", "pcx-collector completed successfully")
        return True
    except subprocess.CalledProcessError as e:
        log("ERROR", f"pcx-collector failed with exit code {e.returncode}")
        return False


class PcxHandler(http.server.SimpleHTTPRequestHandler):
    def translate_path(self, path):
        """Serve static files from /pervasiveCX_mnt/web unless /api/*."""
        path = path.split("?", 1)[0]
        if path.startswith("/api/"):
            return path
        rel = path.lstrip("/") or "index.html"
        return str(Path(WEB_ROOT) / rel)

    def log_message(self, format, *args):
        # suppress default stderr logging
        pass

    def do_GET(self):
        parsed = urllib.parse.urlparse(self.path)
        path = parsed.path

        if path == "/api/dashboard/summary":
            return self.api_dashboard_summary()
        elif path == "/api/servers":
            return self.api_servers()
        elif path == "/api/volumes":
            return self.api_volumes()
        elif path == "/api/captures/recent":
            return self.api_captures_recent()

        return super().do_GET()

    def do_POST(self):
        parsed = urllib.parse.urlparse(self.path)
        path = parsed.path

        if path == "/api/capture/full":
            return self.api_capture_full()

        self.send_error(404, "Not Found")

    def api_dashboard_summary(self):
        try:
            lines = run_psql_query("""
SELECT
  (SELECT COUNT(*) FROM server) AS total_servers,
  (SELECT COUNT(*) FROM capture_session) AS total_captures,
  (SELECT started_at FROM capture_session ORDER BY started_at DESC LIMIT 1) AS last_capture_time,
  (SELECT status FROM capture_session ORDER BY started_at DESC LIMIT 1) AS last_capture_status;
""")
            if not lines or lines == ['']:
                obj = {
                    "total_servers": 0,
                    "total_captures": 0,
                    "last_capture_time": None,
                    "last_capture_status": None,
                }
            else:
                parts = lines[0].split("|")
                obj = {
                    "total_servers": int(parts[0]) if parts[0] else 0,
                    "total_captures": int(parts[1]) if parts[1] else 0,
                    "last_capture_time": parts[2] or None,
                    "last_capture_status": parts[3] or None,
                }
            return to_json_response(self, obj)
        except Exception as e:
            log("ERROR", f"/api/dashboard/summary: {e}")
            return to_json_response(self, {"error": str(e)}, status=500)

    def api_servers(self):
        try:
            lines = run_psql_query("""
SELECT id, code, hostname, environment, os_name, os_version,
       cpu_cores, ram_mb, created_at, updated_at
FROM server
ORDER BY created_at DESC;
""")
        except Exception as e:
            log("ERROR", f"/api/servers: {e}")
            return to_json_response(self, {"error": str(e)}, status=500)

        rows = []
        for line in lines:
            if not line:
                continue
            p = line.split("|")
            rows.append({
                "id": int(p[0]),
                "code": p[1],
                "hostname": p[2],
                "environment": p[3],
                "os_name": p[4],
                "os_version": p[5],
                "cpu_cores": int(p[6]) if p[6] else None,
                "ram_mb": int(p[7]) if p[7] else None,
                "created_at": p[8],
                "updated_at": p[9],
            })
        return to_json_response(self, rows)

    def api_volumes(self):
        try:
            lines = run_psql_query("""
SELECT sv.server_id,
       s.code,
       sv.mount_point,
       sv.total_gb,
       sv.used_gb,
       sv.available_gb,
       sv.usage_percent
FROM server_volume sv
JOIN server s ON s.id = sv.server_id
ORDER BY sv.id DESC
LIMIT 100;
""")
        except Exception as e:
            log("ERROR", f"/api/volumes: {e}")
            return to_json_response(self, {"error": str(e)}, status=500)

        rows = []
        for line in lines:
            if not line:
                continue
            p = line.split("|")
            rows.append({
                "server_id": int(p[0]),
                "server_code": p[1],
                "mount_point": p[2],
                "total_gb": float(p[3]) if p[3] else None,
                "used_gb": float(p[4]) if p[4] else None,
                "available_gb": float(p[5]) if p[5] else None,
                "usage_percent": float(p[6]) if p[6] else None,
            })
        return to_json_response(self, rows)

    def api_captures_recent(self):
        try:
            lines = run_psql_query("""
SELECT id, started_at, ended_at, status, trigger_type, triggered_by, notes
FROM capture_session
ORDER BY started_at DESC
LIMIT 50;
""")
        except Exception as e:
            log("ERROR", f"/api/captures/recent: {e}")
            return to_json_response(self, {"error": str(e)}, status=500)

        rows = []
        for line in lines:
            if not line:
                continue
            p = line.split("|")
            rows.append({
                "id": p[0],
                "started_at": p[1],
                "ended_at": p[2] or None,
                "status": p[3],
                "trigger_type": p[4],
                "triggered_by": p[5],
                "notes": p[6],
            })
        return to_json_response(self, rows)

    def api_capture_full(self):
        length = int(self.headers.get("Content-Length", 0) or 0)
        if length:
            _ = self.rfile.read(length)

        log("INFO", "Capture API called via UI")
        ok = trigger_full_capture()
        if ok:
            return to_json_response(self, {"ok": True})
        else:
            return to_json_response(self, {"ok": False, "error": "collector_failed"}, status=500)


def to_json_response(handler, obj, status=200):
    data = json.dumps(obj, default=str).encode("utf-8")
    handler.send_response(status)
    handler.send_header("Content-Type", "application/json")
    handler.send_header("Content-Length", str(len(data)))
    handler.end_headers()
    handler.wfile.write(data)


def main():
    load_env()
    bind = os.environ.get("PCX_WEB_BIND", "0.0.0.0")
    port = int(os.environ.get("PCX_WEB_PORT", "9494"))

    os.chdir(WEB_ROOT)
    handler = PcxHandler

    with socketserver.TCPServer((bind, port), handler) as httpd:
        log("INFO", f"pcx-app server starting on {bind}:{port}")
        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            log("INFO", "pcx-app shutting down")


if __name__ == "__main__":
    main()
